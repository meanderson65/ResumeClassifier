# Resume Categorization

This project focuses on developing a machine learning model to automatically categorize resumes into predefined job-related categories, such as Data Science, Software Development & QA, Sales & Marketing, based on the textual content within each resume. The primary objective is to streamline the recruitment process by automating resume screening, thereby reducing the time and effort required for initial candidate evaluation.

## Overview

The model analyzes text data, including job descriptions, skills, education, and experience, to assign each resume to the most relevant category. The process involves several steps, including data wrangling, text preprocessing, vectorization, dimensionality reduction, and classification. The final model aims to be robust and accurate, making it a valuable tool for recruiters and HR professionals.

## Techniques Used

### Dimensionality Reduction
- **LSA (TruncatedSVD)**: Reduces the dimensionality of text data while capturing the underlying semantic structure.
- **CNN (Convolutional Neural Networks)**: A deep learning approach that directly learns features from text data.
- **PCA (Principal Component Analysis)**: Transforms features into principal components to reduce dimensionality.

### Classification
- **Logistic Regression**: Used for binary and multi-class classification to estimate the probability of a class based on feature inputs.
- **Naive Bayes**: A probabilistic classifier based on Bayes' theorem, which assumes independence between features.

## Project Workflow

The project is organized into the following steps:

1. **Data Wrangling**: Handling 363 resumes and placing their data into a `.csv` file.
2. **Import Libraries**: Includes libraries for shallow learning (scikit-learn) and deep learning (TensorFlow).
3. **Load Data**: Loading the `.csv` file into the project.
4. **Exploratory Data Analysis (EDA)**: Understanding the distribution and structure of the data.
5. **Test and Train Split**: Dividing the dataset into training and testing sets.
6. **Pre-Processing**: Cleaning and preparing the data for modeling.
7. **Vectorization**: Converting text data into numerical format using `TfidfVectorizer`.
8. **Dimensionality Reduction**:
   - **LSA (TruncatedSVD)**
   - **CNN**
   - **PCA**
9. **Classification**:
   - **CNN (Logistic Regression)**
   - **PCA (Naive Bayes)**
10. **Model Optimization**: Fine-tuning model hyperparameters for better performance.
11. **Model Evaluation**: Assessing the performance of different models.
12. **Model Deployment**: Preparing the final model for use in real-world applications.

## Results

The results include a comparison of the performance of various models and techniques used in this project. The best-performing model is selected based on accuracy and other evaluation metrics.

## Conclusion

This project demonstrates the effectiveness of combining text preprocessing, vectorization, dimensionality reduction, and classification techniques to build an accurate and efficient resume categorization model. The final model can significantly aid in automating the resume screening process, making recruitment faster and more efficient.

---

Feel free to explore the code and contribute to the project!
